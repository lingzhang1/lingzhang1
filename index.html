<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 16px
    }
    
    strong {
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }
    
    heading {
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 24px;
    }
    
    papertitle {
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 700
    }
    
    name {
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 36px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      /* background-color: #ffffd0; */
    }
  </style>
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <title>Ling Zhang</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Galdeano' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Ling Zhang</name>
              </p>
              <p>
                I graduated from the Dept. Electrical Engineering at The City College of New York, CUNY. I have worked on unsupervised feature learning for point cloud with the Graph Convolutional Neural Netowrks under 
                the supervision of Professor <a href="http://ccvcl.org/professor-zhigang-zhu/">Zhigang Zhu</a> at <a href="http://www-cs.ccny.cuny.edu/~zhu/CcvcL/index.html"> </a>CCVCL Lab. I also worked on vehicle
                re-identification and tracking under the supervision of Professor <a href="https://scholar.google.com/citations?user=aAWeB4wAAAAJ&hl=en">Yingli Tian</a> at <a href="http://media-lab.ccny.cuny.edu/wordpress/people/"> </a>CCNY Media Lab.
                  
              </p>
              <p align=center>
                <a href="mailto:dearlingzhang@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/LingZhang-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/lingzhang1"> Github </a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=_o1rStQAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/ling-zhang-cs/"> LinkedIn </a>
              </p>
            </td>
            <td width="33%">
              <img src="images/ling.png" width="250px">
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Publications</heading>
              <!-- <p>
                I am interested in computer vision, machine learning, and image processing. Most of my research is about video analysis such as human action recognition, video feature self-supervised learning, and video feature learning from noisy data. I have also worked in weakly supervised semantic segmentation and lung nodule segmentation in CT scans with Generative Adversarial Networks.</span>
              </p> -->
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
            <td width="25%">
              <div class="one">
                  <div class="two" id='motionblur_image'><img src='images/3DV.png' width="160px" height="160px"></div>
                <img src='images/3DV.png' width="160px" height="160px">
              </div>
              <script type="text/javascript">
                function unprocessing_start() {
                  document.getElementById('unprocessing_image').style.opacity = "1";
                }

                function unprocessing_stop() {
                  document.getElementById('unprocessing_image').style.opacity = "0";
                }
                unprocessing_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/pdf/1904.12359.pdf">
                <papertitle>Unsupervised Feature Learning for Point Cloud by Contrasting and Clustering With Graph Convolutional Neural Network</papertitle>
              </a>
              <br>
              <strong>Ling Zhang</strong>,
              <a href="http://ccvcl.org/professor-zhigang-zhu/">Zhigang Zhu</a>
              <br>
              <em>3DV</em>, 2019
              <br>
              <a href="https://arxiv.org/pdf/1904.12359.pdf">PDF</a> /
	      <!-- <a href="">Slides</a> / -->
	      <a href="data/3dv_poster.pdf">Poster</a>
              <p></p>
              <p>we propose an unsupervised learning approach to learn features from unlabeled point cloud ”3D object” dataset by using part contrasting and object clustering with deep graph neural networks (GNNs). </p>
            </td>
          </tr>


          <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
            <td width="25%">
              <div class="one">
                  <div class="two" id='motionblur_image'><img src='images/CVPRW19.png' width="160px" height="160px"></div>
                <img src='images/CVPRW19.png' width="160px" height="160px">
              </div>
              <script type="text/javascript">
                function unprocessing_start() {
                  document.getElementById('unprocessing_image').style.opacity = "1";
                }

                function unprocessing_stop() {
                  document.getElementById('unprocessing_image').style.opacity = "0";
                }
                unprocessing_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://scene-understanding.com/papers/ContrastNet_CVPRW.pdf">
                <papertitle>Unsupervised Feature Learning for Point Cloud by Contrasting and Clustering With Graph Convolutional Neural Network</papertitle>
              </a>
              <br>
              <strong>Ling Zhang</strong>,
              <a href="http://ccvcl.org/professor-zhigang-zhu/">Zhigang Zhu</a>
              <br>
              <em>CVPRW</em>, 2019
              <br>
              <a href="https://scene-understanding.com/papers/ContrastNet_CVPRW.pdf">PDF</a>
	      <!-- <a href="">Slides</a> / -->
	      <!-- <a href="data/cvpr19_poster_AICITY.pdf">Poster</a> -->
              <p></p>
              <p> we propose an unsupervised learning approach to learn features from unlabeled point cloud ”3D object” dataset by using part contrasting and object clustering with deep graph neural networks (GNNs). </p>
            </td>
          </tr>


          <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
            <td width="25%">
              <div class="one">
                  <div class="two" id='motionblur_image'><img src='images/car-0.png' width="160px" height="160px"></div>
                <img src='images/car-0.png' width="160px" height="160px">
              </div>
              <script type="text/javascript">
                function unprocessing_start() {
                  document.getElementById('unprocessing_image').style.opacity = "1";
                }

                function unprocessing_stop() {
                  document.getElementById('unprocessing_image').style.opacity = "0";
                }
                unprocessing_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Chen_Multi-camera_Vehicle_Tracking_and_Re-identification_on_AI_City_Challenge_2019_CVPRW_2019_paper.pdf">
                <papertitle>Multi-camera Vehicle Tracking and Re-identification on AI City Challenge 2019</papertitle>
              </a>
              <br>
              <a href="https://cyccty.github.io/">Yucheng Chen</a>,
              <a href="https://longlong-jing.github.io/">Longlong Jing</a>,
              <a href="https://www.linkedin.com/in/elahe-vahdani-345675a8/">Elahe Vahdani</a>,
              <strong>Ling Zhang</strong>,
              <a href="http://dianzi.nwpu.edu.cn/info/1269/5955.htm">Mingyi He</a>,
              <a href="http://media-lab.ccny.cuny.edu/wordpress/YLTCCNYHomepage/yltian.html">Yingli Tian</a>              
              <br>
              <em>CVPR AI City Workshop</em>, 2019
              <br>
              <a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Chen_Multi-camera_Vehicle_Tracking_and_Re-identification_on_AI_City_Challenge_2019_CVPRW_2019_paper.pdf">PDF</a> /
	      <!-- <a href="">Slides</a> / -->
	      <a href="data/cvpr19_poster_AICITY.pdf">Poster</a>
              <p></p>
              <p> Our solutions to the image-based vehicle re-identification track and multi-camera vehicle tracking track on AI City Challenge 2019 (AIC2019).  Our proposed
                  framework outperforms the current state-of-the-art vehicle ReID method by 16.3% on Veri dataset. </p>
            </td>
          </tr>

        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
        </td>
    </tr>
  </table>
</body>

</html>
